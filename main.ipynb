{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Jupyter Notebook, I will be \"analyzing\" Leo Tolstoy's classic novel, \"War and Peace, Vol. 1\" in the original Russian language. I've used Python's re (regular expression) and nltk (Natural Language Toolkit) packages to extract and analyze the text of the novel. \n",
    "\n",
    "For the most part, I was practicing regex in this notebook, but I've decided to do a bit more, to get this thing more iteresting, than just writing regex.\n",
    "\n",
    "*P.S. I might add more analysis and regex stuff, stay tuned*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"data/voyna-i-mir-tom-1.txt\", \"r\") as file:\n",
    "    book = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the most common used words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import package to use regex\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4915, 'и'),\n",
       " (2349, 'в'),\n",
       " (1972, 'не'),\n",
       " (1809, 'он'),\n",
       " (1780, 'что'),\n",
       " (1617, 'на'),\n",
       " (1386, 'с'),\n",
       " (1078, 'как'),\n",
       " (871, 'к'),\n",
       " (861, 'я'),\n",
       " (848, 'его'),\n",
       " (780, 'то'),\n",
       " (625, 'князь'),\n",
       " (599, 'но'),\n",
       " (584, 'это'),\n",
       " (570, 'она'),\n",
       " (568, 'сказал'),\n",
       " (498, 'было'),\n",
       " (497, 'за'),\n",
       " (489, 'так')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = re.compile(\"[а-яa-z']+\")\n",
    "matches = re.findall(pattern, book.lower())\n",
    "\n",
    "most_used_words = {}\n",
    "\n",
    "for word in matches:\n",
    "    if word in most_used_words.keys():\n",
    "        most_used_words[word] += 1\n",
    "    else:\n",
    "        most_used_words[word] = 1\n",
    "\n",
    "sorted_words = [(value, key) for (key, value) in most_used_words.items()]\n",
    "\n",
    "sorted_words.sort(reverse=True)\n",
    "\n",
    "sorted_words[:20]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use nlp to remove \"stopwords\" from the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Acer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "# download nltk package with names\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "#get stop words for russian language\n",
    "ru_stopwords = stopwords.words(\"russian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(625, 'князь'),\n",
       " (584, 'это'),\n",
       " (568, 'сказал'),\n",
       " (423, 'вс'),\n",
       " (294, 'андрей'),\n",
       " (228, 'ростов'),\n",
       " (216, 'de'),\n",
       " (213, 'пьер'),\n",
       " (195, 'сказала'),\n",
       " (191, 'говорил'),\n",
       " (183, 'очень'),\n",
       " (176, 'vous'),\n",
       " (171, 'время'),\n",
       " (162, 'который'),\n",
       " (156, 'князя'),\n",
       " (152, 'анна'),\n",
       " (145, 'a'),\n",
       " (142, 'княжна'),\n",
       " (138, 'глаза'),\n",
       " (136, 'лицо')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create new word list without stopwords\n",
    "filtered_words = []\n",
    "\n",
    "for num, word in sorted_words:\n",
    "    if word not in ru_stopwords:\n",
    "        filtered_words.append((num, word))\n",
    "\n",
    "filtered_words[:20]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many chapters are in the book?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = re.compile(\"[ixv]+[\\n\\n]\")\n",
    "matches = re.findall(pattern, book.lower())\n",
    "\n",
    "len(matches)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whats the overall mood of the book?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Acer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'neg': 0.002, 'neu': 0.996, 'pos': 0.001, 'compound': -0.9858}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "nltk.download(\"vader_lexicon\")\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "points = analyzer.polarity_scores(book)\n",
    "points"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In points variable, value pos represents positive sentiment, neg represents negative sentiment, compound sums everything, and its negative, so this means text's sentiment is more negative. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also plan to analyze the most used character names, but i need to figure out whats the best solution to do it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
